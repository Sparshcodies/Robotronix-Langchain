{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c07361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e4c446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de06584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../data/models/pose_landmarker_heavy.task'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f29bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_INPUT_PATH = \"../data/3196221-uhd_3840_2160_25fps.mp4\"\n",
    "VIDEO_OUTPUT_PATH = \"../data/pose_output2.mp4\"\n",
    "CSV_OUTPUT_PATH = \"../data/pose_metrics2.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e0e2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6779a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    num_poses=2,\n",
    "    min_pose_detection_confidence=0.8,\n",
    "    min_tracking_confidence=0.8,\n",
    "    min_pose_presence_confidence=0.8,\n",
    "    output_segmentation_masks=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db7fbbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    if not detection_result.pose_landmarks:\n",
    "        return rgb_image\n",
    "    \n",
    "    annotated_image = rgb_image.copy()\n",
    "    height, width, _ = annotated_image.shape\n",
    "    \n",
    "    POSE_CONNECTIONS = [\n",
    "        (0, 1), (1, 2), (2, 3), (3, 7), (0, 4), (4, 5), (5, 6), (6, 8),\n",
    "        (9, 10), (11, 12), (11, 13), (13, 15), (15, 17), (15, 19), (15, 21),\n",
    "        (17, 19), (12, 14), (14, 16), (16, 18), (16, 20), (16, 22), (18, 20),\n",
    "        (11, 23), (12, 24), (23, 24), (23, 25), (24, 26), (25, 27), (26, 28),\n",
    "        (27, 29), (28, 30), (29, 31), (30, 32), (27, 31), (28, 32)\n",
    "    ]\n",
    "    \n",
    "    for pose_landmarks in detection_result.pose_landmarks:\n",
    "        # Convert normalized coordinates to pixel coordinates\n",
    "        landmark_points = []\n",
    "        for landmark in pose_landmarks:\n",
    "            x = int(landmark.x * width)\n",
    "            y = int(landmark.y * height)\n",
    "            landmark_points.append((x, y))\n",
    "        \n",
    "        # Draw connections (lines between landmarks)\n",
    "        for connection in POSE_CONNECTIONS:\n",
    "            start_idx, end_idx = connection\n",
    "            if start_idx < len(landmark_points) and end_idx < len(landmark_points):\n",
    "                start_point = landmark_points[start_idx]\n",
    "                end_point = landmark_points[end_idx]\n",
    "                cv2.line(annotated_image, start_point, end_point, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw landmarks (circles)\n",
    "        for point in landmark_points:\n",
    "            cv2.circle(annotated_image, point, 5, (0, 0, 255), -1)\n",
    "    \n",
    "    return annotated_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60e6381f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video properties: 2560x1440 @ 25.0 FPS, 385 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 385/385 [01:27<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pose metrics saved to: ../data/pose_metrics2.csv\n",
      "Total records: 682\n",
      "Annotated video saved to: ../data/pose_output2.mp4\n",
      "Processing complete!\n"
     ]
    }
   ],
   "source": [
    "with PoseLandmarker.create_from_options(options) as landmarker:\n",
    "    cap = cv2.VideoCapture(VIDEO_INPUT_PATH)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {VIDEO_INPUT_PATH}\")\n",
    "        exit()\n",
    "    \n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    print(f\"Video properties: {frame_width}x{frame_height} @ {fps} FPS, {total_frames} frames\")\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(VIDEO_OUTPUT_PATH, fourcc, fps, (frame_width, frame_height))\n",
    "    \n",
    "    pose_data = []\n",
    "    \n",
    "    frame_count = 0\n",
    "    with tqdm(total=total_frames, desc=\"Processing\") as pbar:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # Calculate timestamp in milliseconds\n",
    "            frame_timestamp_ms = int(frame_count * 1000 / fps)\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_frame)\n",
    "            pose_landmarker_result = landmarker.detect_for_video(mp_image, frame_timestamp_ms)\n",
    "            annotated_image = draw_landmarks_on_image(rgb_frame, pose_landmarker_result)\n",
    "            annotated_bgr = cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR)\n",
    "            out.write(annotated_bgr)\n",
    "            if pose_landmarker_result.pose_landmarks:\n",
    "                for person_idx, pose_landmarks in enumerate(pose_landmarker_result.pose_landmarks):\n",
    "                    frame_data = {\n",
    "                        'frame': frame_count,\n",
    "                        'timestamp_ms': frame_timestamp_ms,\n",
    "                        'person_id': person_idx\n",
    "                    }\n",
    "                    for landmark_idx, landmark in enumerate(pose_landmarks):\n",
    "                        frame_data[f'landmark_{landmark_idx}_x'] = landmark.x\n",
    "                        frame_data[f'landmark_{landmark_idx}_y'] = landmark.y\n",
    "                        frame_data[f'landmark_{landmark_idx}_z'] = landmark.z\n",
    "                        frame_data[f'landmark_{landmark_idx}_visibility'] = landmark.visibility\n",
    "                    \n",
    "                    pose_data.append(frame_data)\n",
    "            \n",
    "            frame_count += 1\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Release video resources\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    \n",
    "    # Save pose data to CSV\n",
    "    if pose_data:\n",
    "        df = pd.DataFrame(pose_data)\n",
    "        df.to_csv(CSV_OUTPUT_PATH, index=False)\n",
    "        print(f\"\\nPose metrics saved to: {CSV_OUTPUT_PATH}\")\n",
    "        print(f\"Total records: {len(df)}\")\n",
    "    else:\n",
    "        print(\"\\nNo pose landmarks detected in the video.\")\n",
    "    \n",
    "    print(f\"Annotated video saved to: {VIDEO_OUTPUT_PATH}\")\n",
    "    print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06480d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6dcdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
